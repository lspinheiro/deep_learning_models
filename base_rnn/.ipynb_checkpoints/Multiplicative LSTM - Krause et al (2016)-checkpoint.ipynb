{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn.python.ops.core_rnn_cell import RNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def orthogonal_initializer(scale=1.0):\n",
    "    def _initializer(shape, dtype=tf.float32):\n",
    "        flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "        a = np.random.normal(0.0, 1.0, flat_shape)\n",
    "        u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "        q = u if u.shape == flat_shape else v\n",
    "        q = q.reshape(shape)\n",
    "        return tf.constant(scale * q[:shape[0], :shape[1]], dtype=tf.float32)\n",
    "    return _initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiplicativeLSTMCell(RNNCell):\n",
    "    \"\"\"Multiplicative LSTM.\n",
    "       Ben Krause, Liang Lu, Iain Murray, and Steve Renals,\n",
    "       \"Multiplicative LSTM for sequence modelling, \"\n",
    "       in Workshop Track of ICLA 2017,\n",
    "       https://openreview.net/forum?id=SJCS5rXFl&noteId=SJCS5rXFl\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_units,\n",
    "                 cell_clip=None,\n",
    "                 initializer=orthogonal_initializer(),\n",
    "                 forget_bias=1.0,\n",
    "                 activation=tf.tanh):\n",
    "        \"\"\"Initialize the parameters for an LSTM cell.\n",
    "        Args:\n",
    "          num_units: int, The number of units in the LSTM cell.\n",
    "          use_peepholes: bool, set True to enable diagonal/peephole\n",
    "            connections.\n",
    "          cell_clip: (optional) A float value, if provided the cell state\n",
    "            is clipped by this value prior to the cell output activation.\n",
    "          initializer: (optional) The initializer to use for the weight\n",
    "            matrices.\n",
    "          forget_bias: Biases of the forget gate are initialized by default\n",
    "            to 1 in order to reduce the scale of forgetting at the beginning of\n",
    "            the training.\n",
    "          activation: Activation function of the inner states.\n",
    "        \"\"\"\n",
    "        self.num_units = num_units\n",
    "        self.cell_clip = cell_clip\n",
    "        self.initializer = initializer\n",
    "        self.forget_bias = forget_bias\n",
    "        self.activation = activation\n",
    "        self._state_size = tf.contrib.rnn.LSTMStateTuple(num_units, num_units)\n",
    "        self._output_size = num_units\n",
    "\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._state_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_size\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "\n",
    "        \n",
    "        (c_prev, h_prev) = state\n",
    "\n",
    "\n",
    "        dtype = inputs.dtype\n",
    "        input_size = inputs.get_shape().with_rank(2)[1]\n",
    "\n",
    "        with tf.variable_scope(scope or type(self).__name__):\n",
    "            \n",
    "            # Linear calculates eq.18 components\n",
    "            with tf.variable_scope(\"Multipli_Weight\"):\n",
    "                concat = _linear([inputs, h_prev], 2 * self.num_units, True)\n",
    "                \n",
    "            Wmx_xt, Wmh_hprev = tf.split(concat, 2, 1)\n",
    "            m = Wmx_xt * Wmh_hprev  # equation (18)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM_Weight\"):\n",
    "                lstm_matrix = _linear([inputs, m], 4 * self.num_units, True)\n",
    "            i, h_hat, f, o = tf.split(lstm_matrix, 4, 1)\n",
    "            \n",
    "            c = c_prev * tf.sigmoid(f + self.forget_bias) + \\\n",
    "                tf.sigmoid(i) * h_hat\n",
    "\n",
    "            h = self.activation(c * tf.sigmoid(o))\n",
    "\n",
    "\n",
    "            new_state = tf.contrib.rnn.LSTMStateTuple(c, h)\n",
    "            \n",
    "\n",
    "            return h, new_state\n",
    "\n",
    "\n",
    "def _linear(args, output_size, bias, bias_start=0.0, scope=None):\n",
    "    \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
    "    Args:\n",
    "      args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
    "      output_size: int, second dimension of W[i].\n",
    "      bias: boolean, whether to add a bias term or not.\n",
    "      bias_start: starting value to initialize the bias; 0 by default.\n",
    "      scope: VariableScope for the created subgraph; defaults to \"Linear\".\n",
    "    Returns:\n",
    "      A 2D Tensor with shape [batch x output_size] equal to\n",
    "      sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
    "    Raises:\n",
    "      ValueError: if some of the arguments has unspecified or wrong shape.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the total size of arguments on dimension 1.\n",
    "    total_arg_size = 0\n",
    "    shapes = [a.get_shape().as_list() for a in args]\n",
    "    for shape in shapes:\n",
    "            total_arg_size += shape[1]\n",
    "\n",
    "    # Now the computation.\n",
    "    with tf.variable_scope(scope or \"Linear\"):\n",
    "        matrix = tf.get_variable(\"Matrix\", [total_arg_size, output_size])\n",
    "        \n",
    "        res = tf.matmul(tf.concat(args,1), matrix)\n",
    "        \n",
    "        if not bias:\n",
    "            return res\n",
    "        \n",
    "        bias_term = tf.get_variable(\n",
    "            \"Bias\", [output_size],\n",
    "            initializer=tf.constant_initializer(bias_start))\n",
    "    return res + bias_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lstm_cell = MultiplicativeLSTMCell(256, forget_bias=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data set of anna karenatina\n",
    "with open(r'./data/anna.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "vocab = set(text)\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    characters_per_batch = n_seqs * n_steps\n",
    "    n_batches = len(arr)//characters_per_batch\n",
    "    \n",
    "    arr = arr[:n_batches * characters_per_batch]\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        y = np.zeros_like(x)\n",
    "        y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_steps = 50\n",
    "lstm_size = 256\n",
    "num_layers = 1\n",
    "num_classes = len(vocab)\n",
    "learning_rate = 1e-3\n",
    "grad_clip = 5\n",
    "keep_prob_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lstm_graph = tf.Graph()\n",
    "\n",
    "#with lstm_graph.as_default():\n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "cells = [tf.contrib.rnn.DropoutWrapper(\n",
    "    tf.contrib.rnn.BasicLSTMCell(lstm_size), output_keep_prob=keep_prob) for _ in range(num_layers)]\n",
    "# Stack up multiple LSTM layers, for deep learning\n",
    "cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "x_one_hot = tf.one_hot(inputs, num_classes)\n",
    "outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=initial_state)\n",
    "final_state = state\n",
    "\n",
    "seq_output = tf.concat(outputs, axis=1)\n",
    "x = tf.reshape(seq_output, [-1, lstm_size])\n",
    "\n",
    "# Connect the RNN outputs to a softmax layer\n",
    "with tf.variable_scope('softmax'):\n",
    "    softmax_w = tf.Variable(tf.truncated_normal((lstm_size, num_classes), stddev=0.1))\n",
    "    softmax_b = tf.Variable(tf.zeros(num_classes))\n",
    "\n",
    "# Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "# of rows of logit outputs, one for each step and sequence\n",
    "logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "\n",
    "# Use softmax to get the probabilities for predicted characters\n",
    "out = tf.nn.softmax(logits, name='predictions')\n",
    "\n",
    "y_one_hot = tf.one_hot(targets, num_classes)\n",
    "y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "loss=tf.reduce_mean(loss)\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, trainables), grad_clip)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "optimizer = train_op.apply_gradients(list(zip(grads, trainables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file checkpoints already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25...  Training Step: 397...  Training loss: 2.3444...  0.3252 sec/batch\n",
      "Epoch: 2/25...  Training Step: 794...  Training loss: 2.1258...  0.3292 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1191...  Training loss: 1.9859...  0.3837 sec/batch\n",
      "Epoch: 4/25...  Training Step: 1588...  Training loss: 1.8957...  0.3547 sec/batch\n",
      "Epoch: 5/25...  Training Step: 1985...  Training loss: 1.8158...  0.3482 sec/batch\n",
      "Epoch: 6/25...  Training Step: 2382...  Training loss: 1.7633...  0.3197 sec/batch\n",
      "Epoch: 7/25...  Training Step: 2779...  Training loss: 1.7307...  0.3305 sec/batch\n",
      "Epoch: 8/25...  Training Step: 3176...  Training loss: 1.6854...  0.3434 sec/batch\n",
      "Epoch: 9/25...  Training Step: 3573...  Training loss: 1.6625...  0.4337 sec/batch\n",
      "Epoch: 10/25...  Training Step: 3970...  Training loss: 1.6045...  0.3757 sec/batch\n",
      "Epoch: 11/25...  Training Step: 4367...  Training loss: 1.5995...  0.3567 sec/batch\n",
      "Epoch: 12/25...  Training Step: 4764...  Training loss: 1.5736...  0.3479 sec/batch\n",
      "Epoch: 13/25...  Training Step: 5161...  Training loss: 1.5664...  0.5223 sec/batch\n",
      "Epoch: 14/25...  Training Step: 5558...  Training loss: 1.5441...  0.3507 sec/batch\n",
      "Epoch: 15/25...  Training Step: 5955...  Training loss: 1.5446...  0.3327 sec/batch\n",
      "Epoch: 16/25...  Training Step: 6352...  Training loss: 1.5264...  0.3143 sec/batch\n",
      "Epoch: 17/25...  Training Step: 6749...  Training loss: 1.5192...  0.3222 sec/batch\n",
      "Epoch: 18/25...  Training Step: 7146...  Training loss: 1.4891...  0.3232 sec/batch\n",
      "Epoch: 19/25...  Training Step: 7543...  Training loss: 1.4876...  0.3362 sec/batch\n",
      "Epoch: 20/25...  Training Step: 7940...  Training loss: 1.4734...  0.3177 sec/batch\n",
      "Epoch: 21/25...  Training Step: 8337...  Training loss: 1.4654...  0.3142 sec/batch\n",
      "Epoch: 22/25...  Training Step: 8734...  Training loss: 1.4485...  0.3142 sec/batch\n",
      "Epoch: 23/25...  Training Step: 9131...  Training loss: 1.4501...  0.3142 sec/batch\n",
      "Epoch: 24/25...  Training Step: 9528...  Training loss: 1.4325...  0.3130 sec/batch\n",
      "Epoch: 25/25...  Training Step: 9925...  Training loss: 1.4356...  0.3162 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "save_every_n = 5000\n",
    "results = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        new_state = sess.run(initial_state)\n",
    "        \n",
    "        loss_ = 0\n",
    "        \n",
    "        for x_, y_ in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {inputs: x_,\n",
    "                    targets: y_,\n",
    "                    keep_prob: keep_prob_val,\n",
    "                    initial_state: new_state}\n",
    "            \n",
    "            \n",
    "            batch_loss, new_state, _ = sess.run([loss, \n",
    "                                                 final_state, \n",
    "                                                 optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "            end = time.time()\n",
    "            \n",
    "            loss_ += batch_loss\n",
    "            \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "                \n",
    "        print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                  'Training Step: {}... '.format(counter),\n",
    "                  'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "        results.append(loss_)\n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lstm_graph = tf.Graph()\n",
    "\n",
    "#with lstm_graph.as_default():\n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "cells = [tf.contrib.rnn.DropoutWrapper(\n",
    "    MultiplicativeLSTMCell(lstm_size, forget_bias=1.0), output_keep_prob=keep_prob) for _ in range(num_layers)]\n",
    "# Stack up multiple LSTM layers, for deep learning\n",
    "cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "x_one_hot = tf.one_hot(inputs, num_classes)\n",
    "outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=initial_state)\n",
    "final_state = state\n",
    "\n",
    "seq_output = tf.concat(outputs, axis=1)\n",
    "x = tf.reshape(seq_output, [-1, lstm_size])\n",
    "\n",
    "# Connect the RNN outputs to a softmax layer\n",
    "with tf.variable_scope('softmax'):\n",
    "    softmax_w = tf.Variable(tf.truncated_normal((lstm_size, num_classes), stddev=0.1))\n",
    "    softmax_b = tf.Variable(tf.zeros(num_classes))\n",
    "\n",
    "# Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "# of rows of logit outputs, one for each step and sequence\n",
    "logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "\n",
    "# Use softmax to get the probabilities for predicted characters\n",
    "out = tf.nn.softmax(logits, name='predictions')\n",
    "\n",
    "y_one_hot = tf.one_hot(targets, num_classes)\n",
    "y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "loss=tf.reduce_mean(loss)\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, trainables), grad_clip)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "optimizer = train_op.apply_gradients(list(zip(grads, trainables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25...  Training Step: 397...  Training loss: 2.0938...  0.4903 sec/batch\n",
      "Epoch: 2/25...  Training Step: 794...  Training loss: 1.7931...  0.4483 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1191...  Training loss: 1.6816...  0.4533 sec/batch\n",
      "Epoch: 4/25...  Training Step: 1588...  Training loss: 1.5965...  0.4758 sec/batch\n",
      "Epoch: 5/25...  Training Step: 1985...  Training loss: 1.5512...  0.4523 sec/batch\n",
      "Epoch: 6/25...  Training Step: 2382...  Training loss: 1.5200...  0.4494 sec/batch\n",
      "Epoch: 7/25...  Training Step: 2779...  Training loss: 1.4823...  0.4573 sec/batch\n",
      "Epoch: 8/25...  Training Step: 3176...  Training loss: 1.4648...  0.5168 sec/batch\n",
      "Epoch: 9/25...  Training Step: 3573...  Training loss: 1.4504...  0.5286 sec/batch\n",
      "Epoch: 10/25...  Training Step: 3970...  Training loss: 1.4176...  0.4658 sec/batch\n",
      "Epoch: 11/25...  Training Step: 4367...  Training loss: 1.4069...  0.4498 sec/batch\n",
      "Epoch: 12/25...  Training Step: 4764...  Training loss: 1.3961...  0.4578 sec/batch\n",
      "Epoch: 13/25...  Training Step: 5161...  Training loss: 1.3822...  0.4602 sec/batch\n",
      "Epoch: 14/25...  Training Step: 5558...  Training loss: 1.3875...  0.4598 sec/batch\n",
      "Epoch: 15/25...  Training Step: 5955...  Training loss: 1.3682...  0.4598 sec/batch\n",
      "Epoch: 16/25...  Training Step: 6352...  Training loss: 1.3582...  0.4493 sec/batch\n",
      "Epoch: 17/25...  Training Step: 6749...  Training loss: 1.3535...  0.4893 sec/batch\n",
      "Epoch: 18/25...  Training Step: 7146...  Training loss: 1.3412...  0.4858 sec/batch\n",
      "Epoch: 19/25...  Training Step: 7543...  Training loss: 1.3511...  0.4608 sec/batch\n",
      "Epoch: 20/25...  Training Step: 7940...  Training loss: 1.3380...  0.4558 sec/batch\n",
      "Epoch: 21/25...  Training Step: 8337...  Training loss: 1.3247...  0.4963 sec/batch\n",
      "Epoch: 22/25...  Training Step: 8734...  Training loss: 1.3246...  0.5498 sec/batch\n",
      "Epoch: 23/25...  Training Step: 9131...  Training loss: 1.3397...  0.4588 sec/batch\n",
      "Epoch: 24/25...  Training Step: 9528...  Training loss: 1.3357...  0.4443 sec/batch\n",
      "Epoch: 25/25...  Training Step: 9925...  Training loss: 1.3131...  0.4381 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "save_every_n = 5000\n",
    "results2 = []\n",
    "saver2 = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        new_state = sess.run(initial_state)\n",
    "        \n",
    "        loss_ = 0\n",
    "        \n",
    "        for x_, y_ in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {inputs: x_,\n",
    "                    targets: y_,\n",
    "                    keep_prob: keep_prob_val,\n",
    "                    initial_state: new_state}\n",
    "            \n",
    "            \n",
    "            batch_loss, new_state, _ = sess.run([loss, \n",
    "                                                 final_state, \n",
    "                                                 optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "            end = time.time()\n",
    "            \n",
    "            loss_ += batch_loss\n",
    "            \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver2.save(sess, \"checkpoints/i{}_l2{}.ckpt\".format(counter, lstm_size))\n",
    "                \n",
    "        print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                  'Training Step: {}... '.format(counter),\n",
    "                  'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "        results2.append(loss_)\n",
    "    saver2.save(sess, \"checkpoints/i{}_l2{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1076.8895843029022,\n",
       " 870.38367462158203,\n",
       " 800.38399612903595,\n",
       " 754.13296639919281,\n",
       " 721.56226825714111,\n",
       " 697.61929440498352,\n",
       " 678.00555562973022,\n",
       " 662.76907873153687,\n",
       " 649.42015266418457,\n",
       " 638.54171276092529,\n",
       " 629.03574192523956,\n",
       " 621.11004137992859,\n",
       " 614.07727479934692,\n",
       " 607.66338276863098,\n",
       " 602.24304783344269,\n",
       " 597.23441636562347,\n",
       " 592.83621287345886,\n",
       " 588.66394603252411,\n",
       " 584.89007687568665,\n",
       " 581.22994518280029,\n",
       " 578.14372253417969,\n",
       " 575.35523223876953,\n",
       " 572.53971683979034,\n",
       " 570.06412816047668,\n",
       " 567.7631756067276]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1074.1696040630341,\n",
       " 746.16871809959412,\n",
       " 670.88928365707397,\n",
       " 634.63679254055023,\n",
       " 611.99614286422729,\n",
       " 595.69338572025299,\n",
       " 583.82526481151581,\n",
       " 574.38460981845856,\n",
       " 566.94909691810608,\n",
       " 560.59246373176575,\n",
       " 555.20144510269165,\n",
       " 551.11599862575531,\n",
       " 546.76060116291046,\n",
       " 543.49407756328583,\n",
       " 540.06147921085358,\n",
       " 537.52483952045441,\n",
       " 534.84251403808594,\n",
       " 532.77949571609497,\n",
       " 530.3532702922821,\n",
       " 528.18799161911011,\n",
       " 526.55762624740601,\n",
       " 525.02560544013977,\n",
       " 523.29532492160797,\n",
       " 521.60405540466309,\n",
       " 520.64947390556335]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x/8sZkfVcsQBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2751465f6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "p1,=ax.plot(list(range(len(results))), results, label='LSTM')\n",
    "p2,=ax.plot(list(range(len(results2))), results2, label='mLSTM')\n",
    "ax.legend(handles=[p1,p2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
